{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "80e949a67cf278127b748d188dfe995fcb9b6fe4ab79bb80686294a040d0359f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# PyCaret for Machine Learning Algorithm Analysis and Hyperparameter Tuning\n",
    "\n",
    "**Made by: Group 6 in partial completion of Pattern Recognition Class**\n",
    " - Timothy Chan\n",
    " - Rhyle Nodnylson Guinto\n",
    " - Chino Laguda\n",
    " - Randall Joseph Pajaro"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### What is PyCaret?\n",
    " - PyCaret an open source machine learning library designed to automate evaluation and comparison of machine learning algorithms for an ML project.\n",
    " - Apart from Comparison of different Machine Learning Models and their performances on a dataset, PyCaret also offers model tuning. Model Tuning (also known as hyperparameter tuning in some research papers), is a way of getting the best results out of a ML algorithm by making changes to its hyperparameters.\n",
    "\n",
    "#### Sources:\n",
    " - https://machinelearningmastery.com/pycaret-for-machine-learning/\n",
    " - PyCaret: https://pycaret.org/\n",
    " - How to install PyCaret: it's either **pip install pycaret** or **conda install -c conda-forge pycaret**\n",
    "\n",
    "**In summary**, instead of running multiple lines of ML algorithms in order to compare its metrics to see which performs best, and instead of running multiple tests in order to get the best parameters for a ML algorithm, PyCaret automates this process by using only a singular function."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Demonstration using the Customer Happiness Index dataset from the CHI assignment\n",
    "\n",
    "This part would show a demonstration of what PyCaret can do for a machine learning task/project. First off, we import the essential libraries to view the dataset:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   user_profile  load_profile  subscription_profile  \\\n",
       "0            93            66                    92   \n",
       "1            70            36                    72   \n",
       "2            80            66                    90   \n",
       "3            70            80                    82   \n",
       "4            73            56                    62   \n",
       "\n",
       "   customer_experience_profile  customer_support_engagement_profile  \\\n",
       "0                           63                                   76   \n",
       "1                           43                                   53   \n",
       "2                           96                                   50   \n",
       "3                           30                                   50   \n",
       "4                           53                                   76   \n",
       "\n",
       "   customer_profile customer_happiness_index  \n",
       "0                78                    Happy  \n",
       "1                55                Not Happy  \n",
       "2                76                    Happy  \n",
       "3                62                  Neutral  \n",
       "4                64                  Neutral  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_profile</th>\n      <th>load_profile</th>\n      <th>subscription_profile</th>\n      <th>customer_experience_profile</th>\n      <th>customer_support_engagement_profile</th>\n      <th>customer_profile</th>\n      <th>customer_happiness_index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>93</td>\n      <td>66</td>\n      <td>92</td>\n      <td>63</td>\n      <td>76</td>\n      <td>78</td>\n      <td>Happy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>70</td>\n      <td>36</td>\n      <td>72</td>\n      <td>43</td>\n      <td>53</td>\n      <td>55</td>\n      <td>Not Happy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>80</td>\n      <td>66</td>\n      <td>90</td>\n      <td>96</td>\n      <td>50</td>\n      <td>76</td>\n      <td>Happy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>70</td>\n      <td>80</td>\n      <td>82</td>\n      <td>30</td>\n      <td>50</td>\n      <td>62</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>73</td>\n      <td>56</td>\n      <td>62</td>\n      <td>53</td>\n      <td>76</td>\n      <td>64</td>\n      <td>Neutral</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df = pd.read_csv('dataset-happiness-index.csv')\n",
    "df.head()"
   ]
  },
  {
   "source": [
    "We drop **customer_profile** because the column **customer_happiness_index** is already the label column with its string values."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   user_profile  load_profile  subscription_profile  \\\n",
       "0            93            66                    92   \n",
       "1            70            36                    72   \n",
       "2            80            66                    90   \n",
       "3            70            80                    82   \n",
       "4            73            56                    62   \n",
       "\n",
       "   customer_experience_profile  customer_support_engagement_profile  \\\n",
       "0                           63                                   76   \n",
       "1                           43                                   53   \n",
       "2                           96                                   50   \n",
       "3                           30                                   50   \n",
       "4                           53                                   76   \n",
       "\n",
       "  customer_happiness_index  \n",
       "0                    Happy  \n",
       "1                Not Happy  \n",
       "2                    Happy  \n",
       "3                  Neutral  \n",
       "4                  Neutral  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_profile</th>\n      <th>load_profile</th>\n      <th>subscription_profile</th>\n      <th>customer_experience_profile</th>\n      <th>customer_support_engagement_profile</th>\n      <th>customer_happiness_index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>93</td>\n      <td>66</td>\n      <td>92</td>\n      <td>63</td>\n      <td>76</td>\n      <td>Happy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>70</td>\n      <td>36</td>\n      <td>72</td>\n      <td>43</td>\n      <td>53</td>\n      <td>Not Happy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>80</td>\n      <td>66</td>\n      <td>90</td>\n      <td>96</td>\n      <td>50</td>\n      <td>Happy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>70</td>\n      <td>80</td>\n      <td>82</td>\n      <td>30</td>\n      <td>50</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>73</td>\n      <td>56</td>\n      <td>62</td>\n      <td>53</td>\n      <td>76</td>\n      <td>Neutral</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df = df.drop(columns=['customer_profile'])\n",
    "df.head()"
   ]
  },
  {
   "source": [
    "For this data, that will be the only cleaning and preprocessing that would be performed. We use **train_test_split** to split the data for training and testing. We use the train data to run the PyCaret model comparison, because we will be using the train data for the actual model building anyway."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "x = df.loc[:,'user_profile':'customer_support_engagement_profile']\n",
    "# Labels\n",
    "y = df.loc[:,'customer_happiness_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      user_profile  load_profile  subscription_profile  \\\n",
       "582             86            43                    87   \n",
       "159             83            73                    90   \n",
       "1827            70            60                    45   \n",
       "318             80            66                    85   \n",
       "708             70            60                    47   \n",
       "\n",
       "      customer_experience_profile  customer_support_engagement_profile  \\\n",
       "582                            50                                   53   \n",
       "159                            66                                   30   \n",
       "1827                           60                                   43   \n",
       "318                            60                                   53   \n",
       "708                            40                                   56   \n",
       "\n",
       "     customer_happiness_index  \n",
       "582                   Neutral  \n",
       "159                   Neutral  \n",
       "1827                Not Happy  \n",
       "318                   Neutral  \n",
       "708                 Not Happy  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_profile</th>\n      <th>load_profile</th>\n      <th>subscription_profile</th>\n      <th>customer_experience_profile</th>\n      <th>customer_support_engagement_profile</th>\n      <th>customer_happiness_index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>582</th>\n      <td>86</td>\n      <td>43</td>\n      <td>87</td>\n      <td>50</td>\n      <td>53</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>159</th>\n      <td>83</td>\n      <td>73</td>\n      <td>90</td>\n      <td>66</td>\n      <td>30</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>1827</th>\n      <td>70</td>\n      <td>60</td>\n      <td>45</td>\n      <td>60</td>\n      <td>43</td>\n      <td>Not Happy</td>\n    </tr>\n    <tr>\n      <th>318</th>\n      <td>80</td>\n      <td>66</td>\n      <td>85</td>\n      <td>60</td>\n      <td>53</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>708</th>\n      <td>70</td>\n      <td>60</td>\n      <td>47</td>\n      <td>40</td>\n      <td>56</td>\n      <td>Not Happy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "x_train, x_test, y_train, y_test = tts(x, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# This will be our new training data. x_train and y_train combined in one dataframe because x_train and y_train needs to be one dataframe for the PyCaret function, compare_models() to work.\n",
    "train = x_train.copy()\n",
    "train[df.columns[-1]] = y_train.copy()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import setup\n",
    "from pycaret.classification import compare_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                  Model  Accuracy     AUC  Recall   Prec.      F1   Kappa  \\\nlr  Logistic Regression    0.9052  0.9858  0.8153  0.9077  0.9018  0.8182   \n\n       MCC  TT (Sec)  \nlr  0.8212     8.256  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy</th>\n      <th>AUC</th>\n      <th>Recall</th>\n      <th>Prec.</th>\n      <th>F1</th>\n      <th>Kappa</th>\n      <th>MCC</th>\n      <th>TT (Sec)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>lr</th>\n      <td>Logistic Regression</td>\n      <td>0.9052</td>\n      <td>0.9858</td>\n      <td>0.8153</td>\n      <td>0.9077</td>\n      <td>0.9018</td>\n      <td>0.8182</td>\n      <td>0.8212</td>\n      <td>8.256</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                      Model  Accuracy     AUC  Recall   Prec.      F1   Kappa  \\\nlr      Logistic Regression    0.9052  0.9858  0.8153  0.9077  0.9018  0.8182   \nknn  K Neighbors Classifier    0.7703  0.8655  0.5975  0.7660  0.7578  0.5454   \n\n        MCC  TT (Sec)  \nlr   0.8212     8.256  \nknn  0.5513     0.058  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy</th>\n      <th>AUC</th>\n      <th>Recall</th>\n      <th>Prec.</th>\n      <th>F1</th>\n      <th>Kappa</th>\n      <th>MCC</th>\n      <th>TT (Sec)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>lr</th>\n      <td>Logistic Regression</td>\n      <td>0.9052</td>\n      <td>0.9858</td>\n      <td>0.8153</td>\n      <td>0.9077</td>\n      <td>0.9018</td>\n      <td>0.8182</td>\n      <td>0.8212</td>\n      <td>8.256</td>\n    </tr>\n    <tr>\n      <th>knn</th>\n      <td>K Neighbors Classifier</td>\n      <td>0.7703</td>\n      <td>0.8655</td>\n      <td>0.5975</td>\n      <td>0.7660</td>\n      <td>0.7578</td>\n      <td>0.5454</td>\n      <td>0.5513</td>\n      <td>0.058</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                      Model  Accuracy     AUC  Recall   Prec.      F1   Kappa  \\\nlr      Logistic Regression    0.9052  0.9858  0.8153  0.9077  0.9018  0.8182   \nknn  K Neighbors Classifier    0.7703  0.8655  0.5975  0.7660  0.7578  0.5454   \nnb              Naive Bayes    0.1921  0.7366  0.5183  0.6078  0.1391  0.0947   \n\n        MCC  TT (Sec)  \nlr   0.8212     8.256  \nknn  0.5513     0.058  \nnb   0.1474     0.017  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy</th>\n      <th>AUC</th>\n      <th>Recall</th>\n      <th>Prec.</th>\n      <th>F1</th>\n      <th>Kappa</th>\n      <th>MCC</th>\n      <th>TT (Sec)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>lr</th>\n      <td>Logistic Regression</td>\n      <td>0.9052</td>\n      <td>0.9858</td>\n      <td>0.8153</td>\n      <td>0.9077</td>\n      <td>0.9018</td>\n      <td>0.8182</td>\n      <td>0.8212</td>\n      <td>8.256</td>\n    </tr>\n    <tr>\n      <th>knn</th>\n      <td>K Neighbors Classifier</td>\n      <td>0.7703</td>\n      <td>0.8655</td>\n      <td>0.5975</td>\n      <td>0.7660</td>\n      <td>0.7578</td>\n      <td>0.5454</td>\n      <td>0.5513</td>\n      <td>0.058</td>\n    </tr>\n    <tr>\n      <th>nb</th>\n      <td>Naive Bayes</td>\n      <td>0.1921</td>\n      <td>0.7366</td>\n      <td>0.5183</td>\n      <td>0.6078</td>\n      <td>0.1391</td>\n      <td>0.0947</td>\n      <td>0.1474</td>\n      <td>0.017</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                        Model  Accuracy     AUC  Recall   Prec.      F1  \\\nlr        Logistic Regression    0.9052  0.9858  0.8153  0.9077  0.9018   \ndt   Decision Tree Classifier    0.7873  0.8044  0.6904  0.7920  0.7856   \nknn    K Neighbors Classifier    0.7703  0.8655  0.5975  0.7660  0.7578   \nnb                Naive Bayes    0.1921  0.7366  0.5183  0.6078  0.1391   \n\n      Kappa     MCC  TT (Sec)  \nlr   0.8182  0.8212     8.256  \ndt   0.6021  0.6056     0.064  \nknn  0.5454  0.5513     0.058  \nnb   0.0947  0.1474     0.017  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy</th>\n      <th>AUC</th>\n      <th>Recall</th>\n      <th>Prec.</th>\n      <th>F1</th>\n      <th>Kappa</th>\n      <th>MCC</th>\n      <th>TT (Sec)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>lr</th>\n      <td>Logistic Regression</td>\n      <td>0.9052</td>\n      <td>0.9858</td>\n      <td>0.8153</td>\n      <td>0.9077</td>\n      <td>0.9018</td>\n      <td>0.8182</td>\n      <td>0.8212</td>\n      <td>8.256</td>\n    </tr>\n    <tr>\n      <th>dt</th>\n      <td>Decision Tree Classifier</td>\n      <td>0.7873</td>\n      <td>0.8044</td>\n      <td>0.6904</td>\n      <td>0.7920</td>\n      <td>0.7856</td>\n      <td>0.6021</td>\n      <td>0.6056</td>\n      <td>0.064</td>\n    </tr>\n    <tr>\n      <th>knn</th>\n      <td>K Neighbors Classifier</td>\n      <td>0.7703</td>\n      <td>0.8655</td>\n      <td>0.5975</td>\n      <td>0.7660</td>\n      <td>0.7578</td>\n      <td>0.5454</td>\n      <td>0.5513</td>\n      <td>0.058</td>\n    </tr>\n    <tr>\n      <th>nb</th>\n      <td>Naive Bayes</td>\n      <td>0.1921</td>\n      <td>0.7366</td>\n      <td>0.5183</td>\n      <td>0.6078</td>\n      <td>0.1391</td>\n      <td>0.0947</td>\n      <td>0.1474</td>\n      <td>0.017</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                        Model  Accuracy     AUC  Recall   Prec.      F1  \\\nlr        Logistic Regression    0.9052  0.9858  0.8153  0.9077  0.9018   \ndt   Decision Tree Classifier    0.7873  0.8044  0.6904  0.7920  0.7856   \nknn    K Neighbors Classifier    0.7703  0.8655  0.5975  0.7660  0.7578   \nsvm       SVM - Linear Kernel    0.6012  0.0000  0.3728  0.5924  0.5308   \nnb                Naive Bayes    0.1921  0.7366  0.5183  0.6078  0.1391   \n\n      Kappa     MCC  TT (Sec)  \nlr   0.8182  0.8212     8.256  \ndt   0.6021  0.6056     0.064  \nknn  0.5454  0.5513     0.058  \nsvm  0.2779  0.3292     0.055  \nnb   0.0947  0.1474     0.017  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy</th>\n      <th>AUC</th>\n      <th>Recall</th>\n      <th>Prec.</th>\n      <th>F1</th>\n      <th>Kappa</th>\n      <th>MCC</th>\n      <th>TT (Sec)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>lr</th>\n      <td>Logistic Regression</td>\n      <td>0.9052</td>\n      <td>0.9858</td>\n      <td>0.8153</td>\n      <td>0.9077</td>\n      <td>0.9018</td>\n      <td>0.8182</td>\n      <td>0.8212</td>\n      <td>8.256</td>\n    </tr>\n    <tr>\n      <th>dt</th>\n      <td>Decision Tree Classifier</td>\n      <td>0.7873</td>\n      <td>0.8044</td>\n      <td>0.6904</td>\n      <td>0.7920</td>\n      <td>0.7856</td>\n      <td>0.6021</td>\n      <td>0.6056</td>\n      <td>0.064</td>\n    </tr>\n    <tr>\n      <th>knn</th>\n      <td>K Neighbors Classifier</td>\n      <td>0.7703</td>\n      <td>0.8655</td>\n      <td>0.5975</td>\n      <td>0.7660</td>\n      <td>0.7578</td>\n      <td>0.5454</td>\n      <td>0.5513</td>\n      <td>0.058</td>\n    </tr>\n    <tr>\n      <th>svm</th>\n      <td>SVM - Linear Kernel</td>\n      <td>0.6012</td>\n      <td>0.0000</td>\n      <td>0.3728</td>\n      <td>0.5924</td>\n      <td>0.5308</td>\n      <td>0.2779</td>\n      <td>0.3292</td>\n      <td>0.055</td>\n    </tr>\n    <tr>\n      <th>nb</th>\n      <td>Naive Bayes</td>\n      <td>0.1921</td>\n      <td>0.7366</td>\n      <td>0.5183</td>\n      <td>0.6078</td>\n      <td>0.1391</td>\n      <td>0.0947</td>\n      <td>0.1474</td>\n      <td>0.017</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                          Model  Accuracy     AUC  Recall   Prec.      F1  \\\nlr          Logistic Regression    0.9052  0.9858  0.8153  0.9077  0.9018   \ndt     Decision Tree Classifier    0.7873  0.8044  0.6904  0.7920  0.7856   \nknn      K Neighbors Classifier    0.7703  0.8655  0.5975  0.7660  0.7578   \nridge          Ridge Classifier    0.7605  0.0000  0.4490  0.7029  0.7149   \nsvm         SVM - Linear Kernel    0.6012  0.0000  0.3728  0.5924  0.5308   \nnb                  Naive Bayes    0.1921  0.7366  0.5183  0.6078  0.1391   \n\n        Kappa     MCC  TT (Sec)  \nlr     0.8182  0.8212     8.256  \ndt     0.6021  0.6056     0.064  \nknn    0.5454  0.5513     0.058  \nridge  0.4850  0.5082     0.297  \nsvm    0.2779  0.3292     0.055  \nnb     0.0947  0.1474     0.017  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy</th>\n      <th>AUC</th>\n      <th>Recall</th>\n      <th>Prec.</th>\n      <th>F1</th>\n      <th>Kappa</th>\n      <th>MCC</th>\n      <th>TT (Sec)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>lr</th>\n      <td>Logistic Regression</td>\n      <td>0.9052</td>\n      <td>0.9858</td>\n      <td>0.8153</td>\n      <td>0.9077</td>\n      <td>0.9018</td>\n      <td>0.8182</td>\n      <td>0.8212</td>\n      <td>8.256</td>\n    </tr>\n    <tr>\n      <th>dt</th>\n      <td>Decision Tree Classifier</td>\n      <td>0.7873</td>\n      <td>0.8044</td>\n      <td>0.6904</td>\n      <td>0.7920</td>\n      <td>0.7856</td>\n      <td>0.6021</td>\n      <td>0.6056</td>\n      <td>0.064</td>\n    </tr>\n    <tr>\n      <th>knn</th>\n      <td>K Neighbors Classifier</td>\n      <td>0.7703</td>\n      <td>0.8655</td>\n      <td>0.5975</td>\n      <td>0.7660</td>\n      <td>0.7578</td>\n      <td>0.5454</td>\n      <td>0.5513</td>\n      <td>0.058</td>\n    </tr>\n    <tr>\n      <th>ridge</th>\n      <td>Ridge Classifier</td>\n      <td>0.7605</td>\n      <td>0.0000</td>\n      <td>0.4490</td>\n      <td>0.7029</td>\n      <td>0.7149</td>\n      <td>0.4850</td>\n      <td>0.5082</td>\n      <td>0.297</td>\n    </tr>\n    <tr>\n      <th>svm</th>\n      <td>SVM - Linear Kernel</td>\n      <td>0.6012</td>\n      <td>0.0000</td>\n      <td>0.3728</td>\n      <td>0.5924</td>\n      <td>0.5308</td>\n      <td>0.2779</td>\n      <td>0.3292</td>\n      <td>0.055</td>\n    </tr>\n    <tr>\n      <th>nb</th>\n      <td>Naive Bayes</td>\n      <td>0.1921</td>\n      <td>0.7366</td>\n      <td>0.5183</td>\n      <td>0.6078</td>\n      <td>0.1391</td>\n      <td>0.0947</td>\n      <td>0.1474</td>\n      <td>0.017</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                          Model  Accuracy     AUC  Recall   Prec.      F1  \\\nlr          Logistic Regression    0.9052  0.9858  0.8153  0.9077  0.9018   \nrf     Random Forest Classifier    0.8436  0.9578  0.6586  0.8532  0.8272   \ndt     Decision Tree Classifier    0.7873  0.8044  0.6904  0.7920  0.7856   \nknn      K Neighbors Classifier    0.7703  0.8655  0.5975  0.7660  0.7578   \nridge          Ridge Classifier    0.7605  0.0000  0.4490  0.7029  0.7149   \nsvm         SVM - Linear Kernel    0.6012  0.0000  0.3728  0.5924  0.5308   \nnb                  Naive Bayes    0.1921  0.7366  0.5183  0.6078  0.1391   \n\n        Kappa     MCC  TT (Sec)  \nlr     0.8182  0.8212     8.256  \nrf     0.6784  0.6934     0.218  \ndt     0.6021  0.6056     0.064  \nknn    0.5454  0.5513     0.058  \nridge  0.4850  0.5082     0.297  \nsvm    0.2779  0.3292     0.055  \nnb     0.0947  0.1474     0.017  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy</th>\n      <th>AUC</th>\n      <th>Recall</th>\n      <th>Prec.</th>\n      <th>F1</th>\n      <th>Kappa</th>\n      <th>MCC</th>\n      <th>TT (Sec)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>lr</th>\n      <td>Logistic Regression</td>\n      <td>0.9052</td>\n      <td>0.9858</td>\n      <td>0.8153</td>\n      <td>0.9077</td>\n      <td>0.9018</td>\n      <td>0.8182</td>\n      <td>0.8212</td>\n      <td>8.256</td>\n    </tr>\n    <tr>\n      <th>rf</th>\n      <td>Random Forest Classifier</td>\n      <td>0.8436</td>\n      <td>0.9578</td>\n      <td>0.6586</td>\n      <td>0.8532</td>\n      <td>0.8272</td>\n      <td>0.6784</td>\n      <td>0.6934</td>\n      <td>0.218</td>\n    </tr>\n    <tr>\n      <th>dt</th>\n      <td>Decision Tree Classifier</td>\n      <td>0.7873</td>\n      <td>0.8044</td>\n      <td>0.6904</td>\n      <td>0.7920</td>\n      <td>0.7856</td>\n      <td>0.6021</td>\n      <td>0.6056</td>\n      <td>0.064</td>\n    </tr>\n    <tr>\n      <th>knn</th>\n      <td>K Neighbors Classifier</td>\n      <td>0.7703</td>\n      <td>0.8655</td>\n      <td>0.5975</td>\n      <td>0.7660</td>\n      <td>0.7578</td>\n      <td>0.5454</td>\n      <td>0.5513</td>\n      <td>0.058</td>\n    </tr>\n    <tr>\n      <th>ridge</th>\n      <td>Ridge Classifier</td>\n      <td>0.7605</td>\n      <td>0.0000</td>\n      <td>0.4490</td>\n      <td>0.7029</td>\n      <td>0.7149</td>\n      <td>0.4850</td>\n      <td>0.5082</td>\n      <td>0.297</td>\n    </tr>\n    <tr>\n      <th>svm</th>\n      <td>SVM - Linear Kernel</td>\n      <td>0.6012</td>\n      <td>0.0000</td>\n      <td>0.3728</td>\n      <td>0.5924</td>\n      <td>0.5308</td>\n      <td>0.2779</td>\n      <td>0.3292</td>\n      <td>0.055</td>\n    </tr>\n    <tr>\n      <th>nb</th>\n      <td>Naive Bayes</td>\n      <td>0.1921</td>\n      <td>0.7366</td>\n      <td>0.5183</td>\n      <td>0.6078</td>\n      <td>0.1391</td>\n      <td>0.0947</td>\n      <td>0.1474</td>\n      <td>0.017</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                                 Model  Accuracy     AUC  Recall   Prec.  \\\nlr                 Logistic Regression    0.9052  0.9858  0.8153  0.9077   \nrf            Random Forest Classifier    0.8436  0.9578  0.6586  0.8532   \ndt            Decision Tree Classifier    0.7873  0.8044  0.6904  0.7920   \nknn             K Neighbors Classifier    0.7703  0.8655  0.5975  0.7660   \nridge                 Ridge Classifier    0.7605  0.0000  0.4490  0.7029   \nsvm                SVM - Linear Kernel    0.6012  0.0000  0.3728  0.5924   \nqda    Quadratic Discriminant Analysis    0.4255  0.5416  0.3600  0.5113   \nnb                         Naive Bayes    0.1921  0.7366  0.5183  0.6078   \n\n           F1   Kappa     MCC  TT (Sec)  \nlr     0.9018  0.8182  0.8212     8.256  \nrf     0.8272  0.6784  0.6934     0.218  \ndt     0.7856  0.6021  0.6056     0.064  \nknn    0.7578  0.5454  0.5513     0.058  \nridge  0.7149  0.4850  0.5082     0.297  \nsvm    0.5308  0.2779  0.3292     0.055  \nqda    0.4394  0.0849  0.0903     0.033  \nnb     0.1391  0.0947  0.1474     0.017  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy</th>\n      <th>AUC</th>\n      <th>Recall</th>\n      <th>Prec.</th>\n      <th>F1</th>\n      <th>Kappa</th>\n      <th>MCC</th>\n      <th>TT (Sec)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>lr</th>\n      <td>Logistic Regression</td>\n      <td>0.9052</td>\n      <td>0.9858</td>\n      <td>0.8153</td>\n      <td>0.9077</td>\n      <td>0.9018</td>\n      <td>0.8182</td>\n      <td>0.8212</td>\n      <td>8.256</td>\n    </tr>\n    <tr>\n      <th>rf</th>\n      <td>Random Forest Classifier</td>\n      <td>0.8436</td>\n      <td>0.9578</td>\n      <td>0.6586</td>\n      <td>0.8532</td>\n      <td>0.8272</td>\n      <td>0.6784</td>\n      <td>0.6934</td>\n      <td>0.218</td>\n    </tr>\n    <tr>\n      <th>dt</th>\n      <td>Decision Tree Classifier</td>\n      <td>0.7873</td>\n      <td>0.8044</td>\n      <td>0.6904</td>\n      <td>0.7920</td>\n      <td>0.7856</td>\n      <td>0.6021</td>\n      <td>0.6056</td>\n      <td>0.064</td>\n    </tr>\n    <tr>\n      <th>knn</th>\n      <td>K Neighbors Classifier</td>\n      <td>0.7703</td>\n      <td>0.8655</td>\n      <td>0.5975</td>\n      <td>0.7660</td>\n      <td>0.7578</td>\n      <td>0.5454</td>\n      <td>0.5513</td>\n      <td>0.058</td>\n    </tr>\n    <tr>\n      <th>ridge</th>\n      <td>Ridge Classifier</td>\n      <td>0.7605</td>\n      <td>0.0000</td>\n      <td>0.4490</td>\n      <td>0.7029</td>\n      <td>0.7149</td>\n      <td>0.4850</td>\n      <td>0.5082</td>\n      <td>0.297</td>\n    </tr>\n    <tr>\n      <th>svm</th>\n      <td>SVM - Linear Kernel</td>\n      <td>0.6012</td>\n      <td>0.0000</td>\n      <td>0.3728</td>\n      <td>0.5924</td>\n      <td>0.5308</td>\n      <td>0.2779</td>\n      <td>0.3292</td>\n      <td>0.055</td>\n    </tr>\n    <tr>\n      <th>qda</th>\n      <td>Quadratic Discriminant Analysis</td>\n      <td>0.4255</td>\n      <td>0.5416</td>\n      <td>0.3600</td>\n      <td>0.5113</td>\n      <td>0.4394</td>\n      <td>0.0849</td>\n      <td>0.0903</td>\n      <td>0.033</td>\n    </tr>\n    <tr>\n      <th>nb</th>\n      <td>Naive Bayes</td>\n      <td>0.1921</td>\n      <td>0.7366</td>\n      <td>0.5183</td>\n      <td>0.6078</td>\n      <td>0.1391</td>\n      <td>0.0947</td>\n      <td>0.1474</td>\n      <td>0.017</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                                 Model  Accuracy     AUC  Recall   Prec.  \\\nlr                 Logistic Regression    0.9052  0.9858  0.8153  0.9077   \nrf            Random Forest Classifier    0.8436  0.9578  0.6586  0.8532   \ndt            Decision Tree Classifier    0.7873  0.8044  0.6904  0.7920   \nknn             K Neighbors Classifier    0.7703  0.8655  0.5975  0.7660   \nridge                 Ridge Classifier    0.7605  0.0000  0.4490  0.7029   \nada               Ada Boost Classifier    0.6246  0.6336  0.5740  0.6583   \nsvm                SVM - Linear Kernel    0.6012  0.0000  0.3728  0.5924   \nqda    Quadratic Discriminant Analysis    0.4255  0.5416  0.3600  0.5113   \nnb                         Naive Bayes    0.1921  0.7366  0.5183  0.6078   \n\n           F1   Kappa     MCC  TT (Sec)  \nlr     0.9018  0.8182  0.8212     8.256  \nrf     0.8272  0.6784  0.6934     0.218  \ndt     0.7856  0.6021  0.6056     0.064  \nknn    0.7578  0.5454  0.5513     0.058  \nridge  0.7149  0.4850  0.5082     0.297  \nada    0.6210  0.3431  0.3599     0.092  \nsvm    0.5308  0.2779  0.3292     0.055  \nqda    0.4394  0.0849  0.0903     0.033  \nnb     0.1391  0.0947  0.1474     0.017  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy</th>\n      <th>AUC</th>\n      <th>Recall</th>\n      <th>Prec.</th>\n      <th>F1</th>\n      <th>Kappa</th>\n      <th>MCC</th>\n      <th>TT (Sec)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>lr</th>\n      <td>Logistic Regression</td>\n      <td>0.9052</td>\n      <td>0.9858</td>\n      <td>0.8153</td>\n      <td>0.9077</td>\n      <td>0.9018</td>\n      <td>0.8182</td>\n      <td>0.8212</td>\n      <td>8.256</td>\n    </tr>\n    <tr>\n      <th>rf</th>\n      <td>Random Forest Classifier</td>\n      <td>0.8436</td>\n      <td>0.9578</td>\n      <td>0.6586</td>\n      <td>0.8532</td>\n      <td>0.8272</td>\n      <td>0.6784</td>\n      <td>0.6934</td>\n      <td>0.218</td>\n    </tr>\n    <tr>\n      <th>dt</th>\n      <td>Decision Tree Classifier</td>\n      <td>0.7873</td>\n      <td>0.8044</td>\n      <td>0.6904</td>\n      <td>0.7920</td>\n      <td>0.7856</td>\n      <td>0.6021</td>\n      <td>0.6056</td>\n      <td>0.064</td>\n    </tr>\n    <tr>\n      <th>knn</th>\n      <td>K Neighbors Classifier</td>\n      <td>0.7703</td>\n      <td>0.8655</td>\n      <td>0.5975</td>\n      <td>0.7660</td>\n      <td>0.7578</td>\n      <td>0.5454</td>\n      <td>0.5513</td>\n      <td>0.058</td>\n    </tr>\n    <tr>\n      <th>ridge</th>\n      <td>Ridge Classifier</td>\n      <td>0.7605</td>\n      <td>0.0000</td>\n      <td>0.4490</td>\n      <td>0.7029</td>\n      <td>0.7149</td>\n      <td>0.4850</td>\n      <td>0.5082</td>\n      <td>0.297</td>\n    </tr>\n    <tr>\n      <th>ada</th>\n      <td>Ada Boost Classifier</td>\n      <td>0.6246</td>\n      <td>0.6336</td>\n      <td>0.5740</td>\n      <td>0.6583</td>\n      <td>0.6210</td>\n      <td>0.3431</td>\n      <td>0.3599</td>\n      <td>0.092</td>\n    </tr>\n    <tr>\n      <th>svm</th>\n      <td>SVM - Linear Kernel</td>\n      <td>0.6012</td>\n      <td>0.0000</td>\n      <td>0.3728</td>\n      <td>0.5924</td>\n      <td>0.5308</td>\n      <td>0.2779</td>\n      <td>0.3292</td>\n      <td>0.055</td>\n    </tr>\n    <tr>\n      <th>qda</th>\n      <td>Quadratic Discriminant Analysis</td>\n      <td>0.4255</td>\n      <td>0.5416</td>\n      <td>0.3600</td>\n      <td>0.5113</td>\n      <td>0.4394</td>\n      <td>0.0849</td>\n      <td>0.0903</td>\n      <td>0.033</td>\n    </tr>\n    <tr>\n      <th>nb</th>\n      <td>Naive Bayes</td>\n      <td>0.1921</td>\n      <td>0.7366</td>\n      <td>0.5183</td>\n      <td>0.6078</td>\n      <td>0.1391</td>\n      <td>0.0947</td>\n      <td>0.1474</td>\n      <td>0.017</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                                 Model  Accuracy     AUC  Recall   Prec.  \\\nlr                 Logistic Regression    0.9052  0.9858  0.8153  0.9077   \nrf            Random Forest Classifier    0.8436  0.9578  0.6586  0.8532   \ngbc       Gradient Boosting Classifier    0.8427  0.9490  0.7024  0.8431   \ndt            Decision Tree Classifier    0.7873  0.8044  0.6904  0.7920   \nknn             K Neighbors Classifier    0.7703  0.8655  0.5975  0.7660   \nridge                 Ridge Classifier    0.7605  0.0000  0.4490  0.7029   \nada               Ada Boost Classifier    0.6246  0.6336  0.5740  0.6583   \nsvm                SVM - Linear Kernel    0.6012  0.0000  0.3728  0.5924   \nqda    Quadratic Discriminant Analysis    0.4255  0.5416  0.3600  0.5113   \nnb                         Naive Bayes    0.1921  0.7366  0.5183  0.6078   \n\n           F1   Kappa     MCC  TT (Sec)  \nlr     0.9018  0.8182  0.8212     8.256  \nrf     0.8272  0.6784  0.6934     0.218  \ngbc    0.8345  0.6890  0.6954     0.499  \ndt     0.7856  0.6021  0.6056     0.064  \nknn    0.7578  0.5454  0.5513     0.058  \nridge  0.7149  0.4850  0.5082     0.297  \nada    0.6210  0.3431  0.3599     0.092  \nsvm    0.5308  0.2779  0.3292     0.055  \nqda    0.4394  0.0849  0.0903     0.033  \nnb     0.1391  0.0947  0.1474     0.017  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy</th>\n      <th>AUC</th>\n      <th>Recall</th>\n      <th>Prec.</th>\n      <th>F1</th>\n      <th>Kappa</th>\n      <th>MCC</th>\n      <th>TT (Sec)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>lr</th>\n      <td>Logistic Regression</td>\n      <td>0.9052</td>\n      <td>0.9858</td>\n      <td>0.8153</td>\n      <td>0.9077</td>\n      <td>0.9018</td>\n      <td>0.8182</td>\n      <td>0.8212</td>\n      <td>8.256</td>\n    </tr>\n    <tr>\n      <th>rf</th>\n      <td>Random Forest Classifier</td>\n      <td>0.8436</td>\n      <td>0.9578</td>\n      <td>0.6586</td>\n      <td>0.8532</td>\n      <td>0.8272</td>\n      <td>0.6784</td>\n      <td>0.6934</td>\n      <td>0.218</td>\n    </tr>\n    <tr>\n      <th>gbc</th>\n      <td>Gradient Boosting Classifier</td>\n      <td>0.8427</td>\n      <td>0.9490</td>\n      <td>0.7024</td>\n      <td>0.8431</td>\n      <td>0.8345</td>\n      <td>0.6890</td>\n      <td>0.6954</td>\n      <td>0.499</td>\n    </tr>\n    <tr>\n      <th>dt</th>\n      <td>Decision Tree Classifier</td>\n      <td>0.7873</td>\n      <td>0.8044</td>\n      <td>0.6904</td>\n      <td>0.7920</td>\n      <td>0.7856</td>\n      <td>0.6021</td>\n      <td>0.6056</td>\n      <td>0.064</td>\n    </tr>\n    <tr>\n      <th>knn</th>\n      <td>K Neighbors Classifier</td>\n      <td>0.7703</td>\n      <td>0.8655</td>\n      <td>0.5975</td>\n      <td>0.7660</td>\n      <td>0.7578</td>\n      <td>0.5454</td>\n      <td>0.5513</td>\n      <td>0.058</td>\n    </tr>\n    <tr>\n      <th>ridge</th>\n      <td>Ridge Classifier</td>\n      <td>0.7605</td>\n      <td>0.0000</td>\n      <td>0.4490</td>\n      <td>0.7029</td>\n      <td>0.7149</td>\n      <td>0.4850</td>\n      <td>0.5082</td>\n      <td>0.297</td>\n    </tr>\n    <tr>\n      <th>ada</th>\n      <td>Ada Boost Classifier</td>\n      <td>0.6246</td>\n      <td>0.6336</td>\n      <td>0.5740</td>\n      <td>0.6583</td>\n      <td>0.6210</td>\n      <td>0.3431</td>\n      <td>0.3599</td>\n      <td>0.092</td>\n    </tr>\n    <tr>\n      <th>svm</th>\n      <td>SVM - Linear Kernel</td>\n      <td>0.6012</td>\n      <td>0.0000</td>\n      <td>0.3728</td>\n      <td>0.5924</td>\n      <td>0.5308</td>\n      <td>0.2779</td>\n      <td>0.3292</td>\n      <td>0.055</td>\n    </tr>\n    <tr>\n      <th>qda</th>\n      <td>Quadratic Discriminant Analysis</td>\n      <td>0.4255</td>\n      <td>0.5416</td>\n      <td>0.3600</td>\n      <td>0.5113</td>\n      <td>0.4394</td>\n      <td>0.0849</td>\n      <td>0.0903</td>\n      <td>0.033</td>\n    </tr>\n    <tr>\n      <th>nb</th>\n      <td>Naive Bayes</td>\n      <td>0.1921</td>\n      <td>0.7366</td>\n      <td>0.5183</td>\n      <td>0.6078</td>\n      <td>0.1391</td>\n      <td>0.0947</td>\n      <td>0.1474</td>\n      <td>0.017</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                                 Model  Accuracy     AUC  Recall   Prec.  \\\nlr                 Logistic Regression    0.9052  0.9858  0.8153  0.9077   \nlda       Linear Discriminant Analysis    0.8937  0.9835  0.8072  0.8990   \nrf            Random Forest Classifier    0.8436  0.9578  0.6586  0.8532   \ngbc       Gradient Boosting Classifier    0.8427  0.9490  0.7024  0.8431   \ndt            Decision Tree Classifier    0.7873  0.8044  0.6904  0.7920   \nknn             K Neighbors Classifier    0.7703  0.8655  0.5975  0.7660   \nridge                 Ridge Classifier    0.7605  0.0000  0.4490  0.7029   \nada               Ada Boost Classifier    0.6246  0.6336  0.5740  0.6583   \nsvm                SVM - Linear Kernel    0.6012  0.0000  0.3728  0.5924   \nqda    Quadratic Discriminant Analysis    0.4255  0.5416  0.3600  0.5113   \nnb                         Naive Bayes    0.1921  0.7366  0.5183  0.6078   \n\n           F1   Kappa     MCC  TT (Sec)  \nlr     0.9018  0.8182  0.8212     8.256  \nlda    0.8938  0.8048  0.8066     0.126  \nrf     0.8272  0.6784  0.6934     0.218  \ngbc    0.8345  0.6890  0.6954     0.499  \ndt     0.7856  0.6021  0.6056     0.064  \nknn    0.7578  0.5454  0.5513     0.058  \nridge  0.7149  0.4850  0.5082     0.297  \nada    0.6210  0.3431  0.3599     0.092  \nsvm    0.5308  0.2779  0.3292     0.055  \nqda    0.4394  0.0849  0.0903     0.033  \nnb     0.1391  0.0947  0.1474     0.017  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy</th>\n      <th>AUC</th>\n      <th>Recall</th>\n      <th>Prec.</th>\n      <th>F1</th>\n      <th>Kappa</th>\n      <th>MCC</th>\n      <th>TT (Sec)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>lr</th>\n      <td>Logistic Regression</td>\n      <td>0.9052</td>\n      <td>0.9858</td>\n      <td>0.8153</td>\n      <td>0.9077</td>\n      <td>0.9018</td>\n      <td>0.8182</td>\n      <td>0.8212</td>\n      <td>8.256</td>\n    </tr>\n    <tr>\n      <th>lda</th>\n      <td>Linear Discriminant Analysis</td>\n      <td>0.8937</td>\n      <td>0.9835</td>\n      <td>0.8072</td>\n      <td>0.8990</td>\n      <td>0.8938</td>\n      <td>0.8048</td>\n      <td>0.8066</td>\n      <td>0.126</td>\n    </tr>\n    <tr>\n      <th>rf</th>\n      <td>Random Forest Classifier</td>\n      <td>0.8436</td>\n      <td>0.9578</td>\n      <td>0.6586</td>\n      <td>0.8532</td>\n      <td>0.8272</td>\n      <td>0.6784</td>\n      <td>0.6934</td>\n      <td>0.218</td>\n    </tr>\n    <tr>\n      <th>gbc</th>\n      <td>Gradient Boosting Classifier</td>\n      <td>0.8427</td>\n      <td>0.9490</td>\n      <td>0.7024</td>\n      <td>0.8431</td>\n      <td>0.8345</td>\n      <td>0.6890</td>\n      <td>0.6954</td>\n      <td>0.499</td>\n    </tr>\n    <tr>\n      <th>dt</th>\n      <td>Decision Tree Classifier</td>\n      <td>0.7873</td>\n      <td>0.8044</td>\n      <td>0.6904</td>\n      <td>0.7920</td>\n      <td>0.7856</td>\n      <td>0.6021</td>\n      <td>0.6056</td>\n      <td>0.064</td>\n    </tr>\n    <tr>\n      <th>knn</th>\n      <td>K Neighbors Classifier</td>\n      <td>0.7703</td>\n      <td>0.8655</td>\n      <td>0.5975</td>\n      <td>0.7660</td>\n      <td>0.7578</td>\n      <td>0.5454</td>\n      <td>0.5513</td>\n      <td>0.058</td>\n    </tr>\n    <tr>\n      <th>ridge</th>\n      <td>Ridge Classifier</td>\n      <td>0.7605</td>\n      <td>0.0000</td>\n      <td>0.4490</td>\n      <td>0.7029</td>\n      <td>0.7149</td>\n      <td>0.4850</td>\n      <td>0.5082</td>\n      <td>0.297</td>\n    </tr>\n    <tr>\n      <th>ada</th>\n      <td>Ada Boost Classifier</td>\n      <td>0.6246</td>\n      <td>0.6336</td>\n      <td>0.5740</td>\n      <td>0.6583</td>\n      <td>0.6210</td>\n      <td>0.3431</td>\n      <td>0.3599</td>\n      <td>0.092</td>\n    </tr>\n    <tr>\n      <th>svm</th>\n      <td>SVM - Linear Kernel</td>\n      <td>0.6012</td>\n      <td>0.0000</td>\n      <td>0.3728</td>\n      <td>0.5924</td>\n      <td>0.5308</td>\n      <td>0.2779</td>\n      <td>0.3292</td>\n      <td>0.055</td>\n    </tr>\n    <tr>\n      <th>qda</th>\n      <td>Quadratic Discriminant Analysis</td>\n      <td>0.4255</td>\n      <td>0.5416</td>\n      <td>0.3600</td>\n      <td>0.5113</td>\n      <td>0.4394</td>\n      <td>0.0849</td>\n      <td>0.0903</td>\n      <td>0.033</td>\n    </tr>\n    <tr>\n      <th>nb</th>\n      <td>Naive Bayes</td>\n      <td>0.1921</td>\n      <td>0.7366</td>\n      <td>0.5183</td>\n      <td>0.6078</td>\n      <td>0.1391</td>\n      <td>0.0947</td>\n      <td>0.1474</td>\n      <td>0.017</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                                 Model  Accuracy     AUC  Recall   Prec.  \\\nlr                 Logistic Regression    0.9052  0.9858  0.8153  0.9077   \nlda       Linear Discriminant Analysis    0.8937  0.9835  0.8072  0.8990   \nrf            Random Forest Classifier    0.8436  0.9578  0.6586  0.8532   \ngbc       Gradient Boosting Classifier    0.8427  0.9490  0.7024  0.8431   \net              Extra Trees Classifier    0.8365  0.9449  0.6697  0.8372   \ndt            Decision Tree Classifier    0.7873  0.8044  0.6904  0.7920   \nknn             K Neighbors Classifier    0.7703  0.8655  0.5975  0.7660   \nridge                 Ridge Classifier    0.7605  0.0000  0.4490  0.7029   \nada               Ada Boost Classifier    0.6246  0.6336  0.5740  0.6583   \nsvm                SVM - Linear Kernel    0.6012  0.0000  0.3728  0.5924   \nqda    Quadratic Discriminant Analysis    0.4255  0.5416  0.3600  0.5113   \nnb                         Naive Bayes    0.1921  0.7366  0.5183  0.6078   \n\n           F1   Kappa     MCC  TT (Sec)  \nlr     0.9018  0.8182  0.8212     8.256  \nlda    0.8938  0.8048  0.8066     0.126  \nrf     0.8272  0.6784  0.6934     0.218  \ngbc    0.8345  0.6890  0.6954     0.499  \net     0.8229  0.6670  0.6794     0.250  \ndt     0.7856  0.6021  0.6056     0.064  \nknn    0.7578  0.5454  0.5513     0.058  \nridge  0.7149  0.4850  0.5082     0.297  \nada    0.6210  0.3431  0.3599     0.092  \nsvm    0.5308  0.2779  0.3292     0.055  \nqda    0.4394  0.0849  0.0903     0.033  \nnb     0.1391  0.0947  0.1474     0.017  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy</th>\n      <th>AUC</th>\n      <th>Recall</th>\n      <th>Prec.</th>\n      <th>F1</th>\n      <th>Kappa</th>\n      <th>MCC</th>\n      <th>TT (Sec)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>lr</th>\n      <td>Logistic Regression</td>\n      <td>0.9052</td>\n      <td>0.9858</td>\n      <td>0.8153</td>\n      <td>0.9077</td>\n      <td>0.9018</td>\n      <td>0.8182</td>\n      <td>0.8212</td>\n      <td>8.256</td>\n    </tr>\n    <tr>\n      <th>lda</th>\n      <td>Linear Discriminant Analysis</td>\n      <td>0.8937</td>\n      <td>0.9835</td>\n      <td>0.8072</td>\n      <td>0.8990</td>\n      <td>0.8938</td>\n      <td>0.8048</td>\n      <td>0.8066</td>\n      <td>0.126</td>\n    </tr>\n    <tr>\n      <th>rf</th>\n      <td>Random Forest Classifier</td>\n      <td>0.8436</td>\n      <td>0.9578</td>\n      <td>0.6586</td>\n      <td>0.8532</td>\n      <td>0.8272</td>\n      <td>0.6784</td>\n      <td>0.6934</td>\n      <td>0.218</td>\n    </tr>\n    <tr>\n      <th>gbc</th>\n      <td>Gradient Boosting Classifier</td>\n      <td>0.8427</td>\n      <td>0.9490</td>\n      <td>0.7024</td>\n      <td>0.8431</td>\n      <td>0.8345</td>\n      <td>0.6890</td>\n      <td>0.6954</td>\n      <td>0.499</td>\n    </tr>\n    <tr>\n      <th>et</th>\n      <td>Extra Trees Classifier</td>\n      <td>0.8365</td>\n      <td>0.9449</td>\n      <td>0.6697</td>\n      <td>0.8372</td>\n      <td>0.8229</td>\n      <td>0.6670</td>\n      <td>0.6794</td>\n      <td>0.250</td>\n    </tr>\n    <tr>\n      <th>dt</th>\n      <td>Decision Tree Classifier</td>\n      <td>0.7873</td>\n      <td>0.8044</td>\n      <td>0.6904</td>\n      <td>0.7920</td>\n      <td>0.7856</td>\n      <td>0.6021</td>\n      <td>0.6056</td>\n      <td>0.064</td>\n    </tr>\n    <tr>\n      <th>knn</th>\n      <td>K Neighbors Classifier</td>\n      <td>0.7703</td>\n      <td>0.8655</td>\n      <td>0.5975</td>\n      <td>0.7660</td>\n      <td>0.7578</td>\n      <td>0.5454</td>\n      <td>0.5513</td>\n      <td>0.058</td>\n    </tr>\n    <tr>\n      <th>ridge</th>\n      <td>Ridge Classifier</td>\n      <td>0.7605</td>\n      <td>0.0000</td>\n      <td>0.4490</td>\n      <td>0.7029</td>\n      <td>0.7149</td>\n      <td>0.4850</td>\n      <td>0.5082</td>\n      <td>0.297</td>\n    </tr>\n    <tr>\n      <th>ada</th>\n      <td>Ada Boost Classifier</td>\n      <td>0.6246</td>\n      <td>0.6336</td>\n      <td>0.5740</td>\n      <td>0.6583</td>\n      <td>0.6210</td>\n      <td>0.3431</td>\n      <td>0.3599</td>\n      <td>0.092</td>\n    </tr>\n    <tr>\n      <th>svm</th>\n      <td>SVM - Linear Kernel</td>\n      <td>0.6012</td>\n      <td>0.0000</td>\n      <td>0.3728</td>\n      <td>0.5924</td>\n      <td>0.5308</td>\n      <td>0.2779</td>\n      <td>0.3292</td>\n      <td>0.055</td>\n    </tr>\n    <tr>\n      <th>qda</th>\n      <td>Quadratic Discriminant Analysis</td>\n      <td>0.4255</td>\n      <td>0.5416</td>\n      <td>0.3600</td>\n      <td>0.5113</td>\n      <td>0.4394</td>\n      <td>0.0849</td>\n      <td>0.0903</td>\n      <td>0.033</td>\n    </tr>\n    <tr>\n      <th>nb</th>\n      <td>Naive Bayes</td>\n      <td>0.1921</td>\n      <td>0.7366</td>\n      <td>0.5183</td>\n      <td>0.6078</td>\n      <td>0.1391</td>\n      <td>0.0947</td>\n      <td>0.1474</td>\n      <td>0.017</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                                   Model  Accuracy     AUC  Recall   Prec.  \\\nlr                   Logistic Regression    0.9052  0.9858  0.8153  0.9077   \nlda         Linear Discriminant Analysis    0.8937  0.9835  0.8072  0.8990   \nxgboost        Extreme Gradient Boosting    0.8606  0.9621  0.7565  0.8647   \nrf              Random Forest Classifier    0.8436  0.9578  0.6586  0.8532   \ngbc         Gradient Boosting Classifier    0.8427  0.9490  0.7024  0.8431   \net                Extra Trees Classifier    0.8365  0.9449  0.6697  0.8372   \ndt              Decision Tree Classifier    0.7873  0.8044  0.6904  0.7920   \nknn               K Neighbors Classifier    0.7703  0.8655  0.5975  0.7660   \nridge                   Ridge Classifier    0.7605  0.0000  0.4490  0.7029   \nada                 Ada Boost Classifier    0.6246  0.6336  0.5740  0.6583   \nsvm                  SVM - Linear Kernel    0.6012  0.0000  0.3728  0.5924   \nqda      Quadratic Discriminant Analysis    0.4255  0.5416  0.3600  0.5113   \nnb                           Naive Bayes    0.1921  0.7366  0.5183  0.6078   \n\n             F1   Kappa     MCC  TT (Sec)  \nlr       0.9018  0.8182  0.8212     8.256  \nlda      0.8938  0.8048  0.8066     0.126  \nxgboost  0.8548  0.7305  0.7342     1.273  \nrf       0.8272  0.6784  0.6934     0.218  \ngbc      0.8345  0.6890  0.6954     0.499  \net       0.8229  0.6670  0.6794     0.250  \ndt       0.7856  0.6021  0.6056     0.064  \nknn      0.7578  0.5454  0.5513     0.058  \nridge    0.7149  0.4850  0.5082     0.297  \nada      0.6210  0.3431  0.3599     0.092  \nsvm      0.5308  0.2779  0.3292     0.055  \nqda      0.4394  0.0849  0.0903     0.033  \nnb       0.1391  0.0947  0.1474     0.017  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy</th>\n      <th>AUC</th>\n      <th>Recall</th>\n      <th>Prec.</th>\n      <th>F1</th>\n      <th>Kappa</th>\n      <th>MCC</th>\n      <th>TT (Sec)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>lr</th>\n      <td>Logistic Regression</td>\n      <td>0.9052</td>\n      <td>0.9858</td>\n      <td>0.8153</td>\n      <td>0.9077</td>\n      <td>0.9018</td>\n      <td>0.8182</td>\n      <td>0.8212</td>\n      <td>8.256</td>\n    </tr>\n    <tr>\n      <th>lda</th>\n      <td>Linear Discriminant Analysis</td>\n      <td>0.8937</td>\n      <td>0.9835</td>\n      <td>0.8072</td>\n      <td>0.8990</td>\n      <td>0.8938</td>\n      <td>0.8048</td>\n      <td>0.8066</td>\n      <td>0.126</td>\n    </tr>\n    <tr>\n      <th>xgboost</th>\n      <td>Extreme Gradient Boosting</td>\n      <td>0.8606</td>\n      <td>0.9621</td>\n      <td>0.7565</td>\n      <td>0.8647</td>\n      <td>0.8548</td>\n      <td>0.7305</td>\n      <td>0.7342</td>\n      <td>1.273</td>\n    </tr>\n    <tr>\n      <th>rf</th>\n      <td>Random Forest Classifier</td>\n      <td>0.8436</td>\n      <td>0.9578</td>\n      <td>0.6586</td>\n      <td>0.8532</td>\n      <td>0.8272</td>\n      <td>0.6784</td>\n      <td>0.6934</td>\n      <td>0.218</td>\n    </tr>\n    <tr>\n      <th>gbc</th>\n      <td>Gradient Boosting Classifier</td>\n      <td>0.8427</td>\n      <td>0.9490</td>\n      <td>0.7024</td>\n      <td>0.8431</td>\n      <td>0.8345</td>\n      <td>0.6890</td>\n      <td>0.6954</td>\n      <td>0.499</td>\n    </tr>\n    <tr>\n      <th>et</th>\n      <td>Extra Trees Classifier</td>\n      <td>0.8365</td>\n      <td>0.9449</td>\n      <td>0.6697</td>\n      <td>0.8372</td>\n      <td>0.8229</td>\n      <td>0.6670</td>\n      <td>0.6794</td>\n      <td>0.250</td>\n    </tr>\n    <tr>\n      <th>dt</th>\n      <td>Decision Tree Classifier</td>\n      <td>0.7873</td>\n      <td>0.8044</td>\n      <td>0.6904</td>\n      <td>0.7920</td>\n      <td>0.7856</td>\n      <td>0.6021</td>\n      <td>0.6056</td>\n      <td>0.064</td>\n    </tr>\n    <tr>\n      <th>knn</th>\n      <td>K Neighbors Classifier</td>\n      <td>0.7703</td>\n      <td>0.8655</td>\n      <td>0.5975</td>\n      <td>0.7660</td>\n      <td>0.7578</td>\n      <td>0.5454</td>\n      <td>0.5513</td>\n      <td>0.058</td>\n    </tr>\n    <tr>\n      <th>ridge</th>\n      <td>Ridge Classifier</td>\n      <td>0.7605</td>\n      <td>0.0000</td>\n      <td>0.4490</td>\n      <td>0.7029</td>\n      <td>0.7149</td>\n      <td>0.4850</td>\n      <td>0.5082</td>\n      <td>0.297</td>\n    </tr>\n    <tr>\n      <th>ada</th>\n      <td>Ada Boost Classifier</td>\n      <td>0.6246</td>\n      <td>0.6336</td>\n      <td>0.5740</td>\n      <td>0.6583</td>\n      <td>0.6210</td>\n      <td>0.3431</td>\n      <td>0.3599</td>\n      <td>0.092</td>\n    </tr>\n    <tr>\n      <th>svm</th>\n      <td>SVM - Linear Kernel</td>\n      <td>0.6012</td>\n      <td>0.0000</td>\n      <td>0.3728</td>\n      <td>0.5924</td>\n      <td>0.5308</td>\n      <td>0.2779</td>\n      <td>0.3292</td>\n      <td>0.055</td>\n    </tr>\n    <tr>\n      <th>qda</th>\n      <td>Quadratic Discriminant Analysis</td>\n      <td>0.4255</td>\n      <td>0.5416</td>\n      <td>0.3600</td>\n      <td>0.5113</td>\n      <td>0.4394</td>\n      <td>0.0849</td>\n      <td>0.0903</td>\n      <td>0.033</td>\n    </tr>\n    <tr>\n      <th>nb</th>\n      <td>Naive Bayes</td>\n      <td>0.1921</td>\n      <td>0.7366</td>\n      <td>0.5183</td>\n      <td>0.6078</td>\n      <td>0.1391</td>\n      <td>0.0947</td>\n      <td>0.1474</td>\n      <td>0.017</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                                    Model  Accuracy     AUC  Recall   Prec.  \\\nlr                    Logistic Regression    0.9052  0.9858  0.8153  0.9077   \nlda          Linear Discriminant Analysis    0.8937  0.9835  0.8072  0.8990   \nlightgbm  Light Gradient Boosting Machine    0.8740  0.9653  0.7790  0.8763   \nxgboost         Extreme Gradient Boosting    0.8606  0.9621  0.7565  0.8647   \nrf               Random Forest Classifier    0.8436  0.9578  0.6586  0.8532   \ngbc          Gradient Boosting Classifier    0.8427  0.9490  0.7024  0.8431   \net                 Extra Trees Classifier    0.8365  0.9449  0.6697  0.8372   \ndt               Decision Tree Classifier    0.7873  0.8044  0.6904  0.7920   \nknn                K Neighbors Classifier    0.7703  0.8655  0.5975  0.7660   \nridge                    Ridge Classifier    0.7605  0.0000  0.4490  0.7029   \nada                  Ada Boost Classifier    0.6246  0.6336  0.5740  0.6583   \nsvm                   SVM - Linear Kernel    0.6012  0.0000  0.3728  0.5924   \nqda       Quadratic Discriminant Analysis    0.4255  0.5416  0.3600  0.5113   \nnb                            Naive Bayes    0.1921  0.7366  0.5183  0.6078   \n\n              F1   Kappa     MCC  TT (Sec)  \nlr        0.9018  0.8182  0.8212     8.256  \nlda       0.8938  0.8048  0.8066     0.126  \nlightgbm  0.8693  0.7562  0.7596     1.988  \nxgboost   0.8548  0.7305  0.7342     1.273  \nrf        0.8272  0.6784  0.6934     0.218  \ngbc       0.8345  0.6890  0.6954     0.499  \net        0.8229  0.6670  0.6794     0.250  \ndt        0.7856  0.6021  0.6056     0.064  \nknn       0.7578  0.5454  0.5513     0.058  \nridge     0.7149  0.4850  0.5082     0.297  \nada       0.6210  0.3431  0.3599     0.092  \nsvm       0.5308  0.2779  0.3292     0.055  \nqda       0.4394  0.0849  0.0903     0.033  \nnb        0.1391  0.0947  0.1474     0.017  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy</th>\n      <th>AUC</th>\n      <th>Recall</th>\n      <th>Prec.</th>\n      <th>F1</th>\n      <th>Kappa</th>\n      <th>MCC</th>\n      <th>TT (Sec)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>lr</th>\n      <td>Logistic Regression</td>\n      <td>0.9052</td>\n      <td>0.9858</td>\n      <td>0.8153</td>\n      <td>0.9077</td>\n      <td>0.9018</td>\n      <td>0.8182</td>\n      <td>0.8212</td>\n      <td>8.256</td>\n    </tr>\n    <tr>\n      <th>lda</th>\n      <td>Linear Discriminant Analysis</td>\n      <td>0.8937</td>\n      <td>0.9835</td>\n      <td>0.8072</td>\n      <td>0.8990</td>\n      <td>0.8938</td>\n      <td>0.8048</td>\n      <td>0.8066</td>\n      <td>0.126</td>\n    </tr>\n    <tr>\n      <th>lightgbm</th>\n      <td>Light Gradient Boosting Machine</td>\n      <td>0.8740</td>\n      <td>0.9653</td>\n      <td>0.7790</td>\n      <td>0.8763</td>\n      <td>0.8693</td>\n      <td>0.7562</td>\n      <td>0.7596</td>\n      <td>1.988</td>\n    </tr>\n    <tr>\n      <th>xgboost</th>\n      <td>Extreme Gradient Boosting</td>\n      <td>0.8606</td>\n      <td>0.9621</td>\n      <td>0.7565</td>\n      <td>0.8647</td>\n      <td>0.8548</td>\n      <td>0.7305</td>\n      <td>0.7342</td>\n      <td>1.273</td>\n    </tr>\n    <tr>\n      <th>rf</th>\n      <td>Random Forest Classifier</td>\n      <td>0.8436</td>\n      <td>0.9578</td>\n      <td>0.6586</td>\n      <td>0.8532</td>\n      <td>0.8272</td>\n      <td>0.6784</td>\n      <td>0.6934</td>\n      <td>0.218</td>\n    </tr>\n    <tr>\n      <th>gbc</th>\n      <td>Gradient Boosting Classifier</td>\n      <td>0.8427</td>\n      <td>0.9490</td>\n      <td>0.7024</td>\n      <td>0.8431</td>\n      <td>0.8345</td>\n      <td>0.6890</td>\n      <td>0.6954</td>\n      <td>0.499</td>\n    </tr>\n    <tr>\n      <th>et</th>\n      <td>Extra Trees Classifier</td>\n      <td>0.8365</td>\n      <td>0.9449</td>\n      <td>0.6697</td>\n      <td>0.8372</td>\n      <td>0.8229</td>\n      <td>0.6670</td>\n      <td>0.6794</td>\n      <td>0.250</td>\n    </tr>\n    <tr>\n      <th>dt</th>\n      <td>Decision Tree Classifier</td>\n      <td>0.7873</td>\n      <td>0.8044</td>\n      <td>0.6904</td>\n      <td>0.7920</td>\n      <td>0.7856</td>\n      <td>0.6021</td>\n      <td>0.6056</td>\n      <td>0.064</td>\n    </tr>\n    <tr>\n      <th>knn</th>\n      <td>K Neighbors Classifier</td>\n      <td>0.7703</td>\n      <td>0.8655</td>\n      <td>0.5975</td>\n      <td>0.7660</td>\n      <td>0.7578</td>\n      <td>0.5454</td>\n      <td>0.5513</td>\n      <td>0.058</td>\n    </tr>\n    <tr>\n      <th>ridge</th>\n      <td>Ridge Classifier</td>\n      <td>0.7605</td>\n      <td>0.0000</td>\n      <td>0.4490</td>\n      <td>0.7029</td>\n      <td>0.7149</td>\n      <td>0.4850</td>\n      <td>0.5082</td>\n      <td>0.297</td>\n    </tr>\n    <tr>\n      <th>ada</th>\n      <td>Ada Boost Classifier</td>\n      <td>0.6246</td>\n      <td>0.6336</td>\n      <td>0.5740</td>\n      <td>0.6583</td>\n      <td>0.6210</td>\n      <td>0.3431</td>\n      <td>0.3599</td>\n      <td>0.092</td>\n    </tr>\n    <tr>\n      <th>svm</th>\n      <td>SVM - Linear Kernel</td>\n      <td>0.6012</td>\n      <td>0.0000</td>\n      <td>0.3728</td>\n      <td>0.5924</td>\n      <td>0.5308</td>\n      <td>0.2779</td>\n      <td>0.3292</td>\n      <td>0.055</td>\n    </tr>\n    <tr>\n      <th>qda</th>\n      <td>Quadratic Discriminant Analysis</td>\n      <td>0.4255</td>\n      <td>0.5416</td>\n      <td>0.3600</td>\n      <td>0.5113</td>\n      <td>0.4394</td>\n      <td>0.0849</td>\n      <td>0.0903</td>\n      <td>0.033</td>\n    </tr>\n    <tr>\n      <th>nb</th>\n      <td>Naive Bayes</td>\n      <td>0.1921</td>\n      <td>0.7366</td>\n      <td>0.5183</td>\n      <td>0.6078</td>\n      <td>0.1391</td>\n      <td>0.0947</td>\n      <td>0.1474</td>\n      <td>0.017</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                                    Model  Accuracy     AUC  Recall   Prec.  \\\nlr                    Logistic Regression    0.9052  0.9858  0.8153  0.9077   \ncatboost              CatBoost Classifier    0.8990  0.9832  0.8054  0.9026   \nlda          Linear Discriminant Analysis    0.8937  0.9835  0.8072  0.8990   \nlightgbm  Light Gradient Boosting Machine    0.8740  0.9653  0.7790  0.8763   \nxgboost         Extreme Gradient Boosting    0.8606  0.9621  0.7565  0.8647   \nrf               Random Forest Classifier    0.8436  0.9578  0.6586  0.8532   \ngbc          Gradient Boosting Classifier    0.8427  0.9490  0.7024  0.8431   \net                 Extra Trees Classifier    0.8365  0.9449  0.6697  0.8372   \ndt               Decision Tree Classifier    0.7873  0.8044  0.6904  0.7920   \nknn                K Neighbors Classifier    0.7703  0.8655  0.5975  0.7660   \nridge                    Ridge Classifier    0.7605  0.0000  0.4490  0.7029   \nada                  Ada Boost Classifier    0.6246  0.6336  0.5740  0.6583   \nsvm                   SVM - Linear Kernel    0.6012  0.0000  0.3728  0.5924   \nqda       Quadratic Discriminant Analysis    0.4255  0.5416  0.3600  0.5113   \nnb                            Naive Bayes    0.1921  0.7366  0.5183  0.6078   \n\n              F1   Kappa     MCC  TT (Sec)  \nlr        0.9018  0.8182  0.8212     8.256  \ncatboost  0.8949  0.8047  0.8087     2.033  \nlda       0.8938  0.8048  0.8066     0.126  \nlightgbm  0.8693  0.7562  0.7596     1.988  \nxgboost   0.8548  0.7305  0.7342     1.273  \nrf        0.8272  0.6784  0.6934     0.218  \ngbc       0.8345  0.6890  0.6954     0.499  \net        0.8229  0.6670  0.6794     0.250  \ndt        0.7856  0.6021  0.6056     0.064  \nknn       0.7578  0.5454  0.5513     0.058  \nridge     0.7149  0.4850  0.5082     0.297  \nada       0.6210  0.3431  0.3599     0.092  \nsvm       0.5308  0.2779  0.3292     0.055  \nqda       0.4394  0.0849  0.0903     0.033  \nnb        0.1391  0.0947  0.1474     0.017  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy</th>\n      <th>AUC</th>\n      <th>Recall</th>\n      <th>Prec.</th>\n      <th>F1</th>\n      <th>Kappa</th>\n      <th>MCC</th>\n      <th>TT (Sec)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>lr</th>\n      <td>Logistic Regression</td>\n      <td>0.9052</td>\n      <td>0.9858</td>\n      <td>0.8153</td>\n      <td>0.9077</td>\n      <td>0.9018</td>\n      <td>0.8182</td>\n      <td>0.8212</td>\n      <td>8.256</td>\n    </tr>\n    <tr>\n      <th>catboost</th>\n      <td>CatBoost Classifier</td>\n      <td>0.8990</td>\n      <td>0.9832</td>\n      <td>0.8054</td>\n      <td>0.9026</td>\n      <td>0.8949</td>\n      <td>0.8047</td>\n      <td>0.8087</td>\n      <td>2.033</td>\n    </tr>\n    <tr>\n      <th>lda</th>\n      <td>Linear Discriminant Analysis</td>\n      <td>0.8937</td>\n      <td>0.9835</td>\n      <td>0.8072</td>\n      <td>0.8990</td>\n      <td>0.8938</td>\n      <td>0.8048</td>\n      <td>0.8066</td>\n      <td>0.126</td>\n    </tr>\n    <tr>\n      <th>lightgbm</th>\n      <td>Light Gradient Boosting Machine</td>\n      <td>0.8740</td>\n      <td>0.9653</td>\n      <td>0.7790</td>\n      <td>0.8763</td>\n      <td>0.8693</td>\n      <td>0.7562</td>\n      <td>0.7596</td>\n      <td>1.988</td>\n    </tr>\n    <tr>\n      <th>xgboost</th>\n      <td>Extreme Gradient Boosting</td>\n      <td>0.8606</td>\n      <td>0.9621</td>\n      <td>0.7565</td>\n      <td>0.8647</td>\n      <td>0.8548</td>\n      <td>0.7305</td>\n      <td>0.7342</td>\n      <td>1.273</td>\n    </tr>\n    <tr>\n      <th>rf</th>\n      <td>Random Forest Classifier</td>\n      <td>0.8436</td>\n      <td>0.9578</td>\n      <td>0.6586</td>\n      <td>0.8532</td>\n      <td>0.8272</td>\n      <td>0.6784</td>\n      <td>0.6934</td>\n      <td>0.218</td>\n    </tr>\n    <tr>\n      <th>gbc</th>\n      <td>Gradient Boosting Classifier</td>\n      <td>0.8427</td>\n      <td>0.9490</td>\n      <td>0.7024</td>\n      <td>0.8431</td>\n      <td>0.8345</td>\n      <td>0.6890</td>\n      <td>0.6954</td>\n      <td>0.499</td>\n    </tr>\n    <tr>\n      <th>et</th>\n      <td>Extra Trees Classifier</td>\n      <td>0.8365</td>\n      <td>0.9449</td>\n      <td>0.6697</td>\n      <td>0.8372</td>\n      <td>0.8229</td>\n      <td>0.6670</td>\n      <td>0.6794</td>\n      <td>0.250</td>\n    </tr>\n    <tr>\n      <th>dt</th>\n      <td>Decision Tree Classifier</td>\n      <td>0.7873</td>\n      <td>0.8044</td>\n      <td>0.6904</td>\n      <td>0.7920</td>\n      <td>0.7856</td>\n      <td>0.6021</td>\n      <td>0.6056</td>\n      <td>0.064</td>\n    </tr>\n    <tr>\n      <th>knn</th>\n      <td>K Neighbors Classifier</td>\n      <td>0.7703</td>\n      <td>0.8655</td>\n      <td>0.5975</td>\n      <td>0.7660</td>\n      <td>0.7578</td>\n      <td>0.5454</td>\n      <td>0.5513</td>\n      <td>0.058</td>\n    </tr>\n    <tr>\n      <th>ridge</th>\n      <td>Ridge Classifier</td>\n      <td>0.7605</td>\n      <td>0.0000</td>\n      <td>0.4490</td>\n      <td>0.7029</td>\n      <td>0.7149</td>\n      <td>0.4850</td>\n      <td>0.5082</td>\n      <td>0.297</td>\n    </tr>\n    <tr>\n      <th>ada</th>\n      <td>Ada Boost Classifier</td>\n      <td>0.6246</td>\n      <td>0.6336</td>\n      <td>0.5740</td>\n      <td>0.6583</td>\n      <td>0.6210</td>\n      <td>0.3431</td>\n      <td>0.3599</td>\n      <td>0.092</td>\n    </tr>\n    <tr>\n      <th>svm</th>\n      <td>SVM - Linear Kernel</td>\n      <td>0.6012</td>\n      <td>0.0000</td>\n      <td>0.3728</td>\n      <td>0.5924</td>\n      <td>0.5308</td>\n      <td>0.2779</td>\n      <td>0.3292</td>\n      <td>0.055</td>\n    </tr>\n    <tr>\n      <th>qda</th>\n      <td>Quadratic Discriminant Analysis</td>\n      <td>0.4255</td>\n      <td>0.5416</td>\n      <td>0.3600</td>\n      <td>0.5113</td>\n      <td>0.4394</td>\n      <td>0.0849</td>\n      <td>0.0903</td>\n      <td>0.033</td>\n    </tr>\n    <tr>\n      <th>nb</th>\n      <td>Naive Bayes</td>\n      <td>0.1921</td>\n      <td>0.7366</td>\n      <td>0.5183</td>\n      <td>0.6078</td>\n      <td>0.1391</td>\n      <td>0.0947</td>\n      <td>0.1474</td>\n      <td>0.017</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                                    Model  Accuracy     AUC  Recall   Prec.  \\\nlr                    Logistic Regression    0.9052  0.9858  0.8153  0.9077   \ncatboost              CatBoost Classifier    0.8990  0.9832  0.8054  0.9026   \nlda          Linear Discriminant Analysis    0.8937  0.9835  0.8072  0.8990   \nlightgbm  Light Gradient Boosting Machine    0.8740  0.9653  0.7790  0.8763   \nxgboost         Extreme Gradient Boosting    0.8606  0.9621  0.7565  0.8647   \nrf               Random Forest Classifier    0.8436  0.9578  0.6586  0.8532   \ngbc          Gradient Boosting Classifier    0.8427  0.9490  0.7024  0.8431   \net                 Extra Trees Classifier    0.8365  0.9449  0.6697  0.8372   \ndt               Decision Tree Classifier    0.7873  0.8044  0.6904  0.7920   \nknn                K Neighbors Classifier    0.7703  0.8655  0.5975  0.7660   \nridge                    Ridge Classifier    0.7605  0.0000  0.4490  0.7029   \nada                  Ada Boost Classifier    0.6246  0.6336  0.5740  0.6583   \nsvm                   SVM - Linear Kernel    0.6012  0.0000  0.3728  0.5924   \nqda       Quadratic Discriminant Analysis    0.4255  0.5416  0.3600  0.5113   \nnb                            Naive Bayes    0.1921  0.7366  0.5183  0.6078   \n\n              F1   Kappa     MCC  TT (Sec)  \nlr        0.9018  0.8182  0.8212     8.256  \ncatboost  0.8949  0.8047  0.8087     2.033  \nlda       0.8938  0.8048  0.8066     0.126  \nlightgbm  0.8693  0.7562  0.7596     1.988  \nxgboost   0.8548  0.7305  0.7342     1.273  \nrf        0.8272  0.6784  0.6934     0.218  \ngbc       0.8345  0.6890  0.6954     0.499  \net        0.8229  0.6670  0.6794     0.250  \ndt        0.7856  0.6021  0.6056     0.064  \nknn       0.7578  0.5454  0.5513     0.058  \nridge     0.7149  0.4850  0.5082     0.297  \nada       0.6210  0.3431  0.3599     0.092  \nsvm       0.5308  0.2779  0.3292     0.055  \nqda       0.4394  0.0849  0.0903     0.033  \nnb        0.1391  0.0947  0.1474     0.017  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy</th>\n      <th>AUC</th>\n      <th>Recall</th>\n      <th>Prec.</th>\n      <th>F1</th>\n      <th>Kappa</th>\n      <th>MCC</th>\n      <th>TT (Sec)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>lr</th>\n      <td>Logistic Regression</td>\n      <td>0.9052</td>\n      <td>0.9858</td>\n      <td>0.8153</td>\n      <td>0.9077</td>\n      <td>0.9018</td>\n      <td>0.8182</td>\n      <td>0.8212</td>\n      <td>8.256</td>\n    </tr>\n    <tr>\n      <th>catboost</th>\n      <td>CatBoost Classifier</td>\n      <td>0.8990</td>\n      <td>0.9832</td>\n      <td>0.8054</td>\n      <td>0.9026</td>\n      <td>0.8949</td>\n      <td>0.8047</td>\n      <td>0.8087</td>\n      <td>2.033</td>\n    </tr>\n    <tr>\n      <th>lda</th>\n      <td>Linear Discriminant Analysis</td>\n      <td>0.8937</td>\n      <td>0.9835</td>\n      <td>0.8072</td>\n      <td>0.8990</td>\n      <td>0.8938</td>\n      <td>0.8048</td>\n      <td>0.8066</td>\n      <td>0.126</td>\n    </tr>\n    <tr>\n      <th>lightgbm</th>\n      <td>Light Gradient Boosting Machine</td>\n      <td>0.8740</td>\n      <td>0.9653</td>\n      <td>0.7790</td>\n      <td>0.8763</td>\n      <td>0.8693</td>\n      <td>0.7562</td>\n      <td>0.7596</td>\n      <td>1.988</td>\n    </tr>\n    <tr>\n      <th>xgboost</th>\n      <td>Extreme Gradient Boosting</td>\n      <td>0.8606</td>\n      <td>0.9621</td>\n      <td>0.7565</td>\n      <td>0.8647</td>\n      <td>0.8548</td>\n      <td>0.7305</td>\n      <td>0.7342</td>\n      <td>1.273</td>\n    </tr>\n    <tr>\n      <th>rf</th>\n      <td>Random Forest Classifier</td>\n      <td>0.8436</td>\n      <td>0.9578</td>\n      <td>0.6586</td>\n      <td>0.8532</td>\n      <td>0.8272</td>\n      <td>0.6784</td>\n      <td>0.6934</td>\n      <td>0.218</td>\n    </tr>\n    <tr>\n      <th>gbc</th>\n      <td>Gradient Boosting Classifier</td>\n      <td>0.8427</td>\n      <td>0.9490</td>\n      <td>0.7024</td>\n      <td>0.8431</td>\n      <td>0.8345</td>\n      <td>0.6890</td>\n      <td>0.6954</td>\n      <td>0.499</td>\n    </tr>\n    <tr>\n      <th>et</th>\n      <td>Extra Trees Classifier</td>\n      <td>0.8365</td>\n      <td>0.9449</td>\n      <td>0.6697</td>\n      <td>0.8372</td>\n      <td>0.8229</td>\n      <td>0.6670</td>\n      <td>0.6794</td>\n      <td>0.250</td>\n    </tr>\n    <tr>\n      <th>dt</th>\n      <td>Decision Tree Classifier</td>\n      <td>0.7873</td>\n      <td>0.8044</td>\n      <td>0.6904</td>\n      <td>0.7920</td>\n      <td>0.7856</td>\n      <td>0.6021</td>\n      <td>0.6056</td>\n      <td>0.064</td>\n    </tr>\n    <tr>\n      <th>knn</th>\n      <td>K Neighbors Classifier</td>\n      <td>0.7703</td>\n      <td>0.8655</td>\n      <td>0.5975</td>\n      <td>0.7660</td>\n      <td>0.7578</td>\n      <td>0.5454</td>\n      <td>0.5513</td>\n      <td>0.058</td>\n    </tr>\n    <tr>\n      <th>ridge</th>\n      <td>Ridge Classifier</td>\n      <td>0.7605</td>\n      <td>0.0000</td>\n      <td>0.4490</td>\n      <td>0.7029</td>\n      <td>0.7149</td>\n      <td>0.4850</td>\n      <td>0.5082</td>\n      <td>0.297</td>\n    </tr>\n    <tr>\n      <th>ada</th>\n      <td>Ada Boost Classifier</td>\n      <td>0.6246</td>\n      <td>0.6336</td>\n      <td>0.5740</td>\n      <td>0.6583</td>\n      <td>0.6210</td>\n      <td>0.3431</td>\n      <td>0.3599</td>\n      <td>0.092</td>\n    </tr>\n    <tr>\n      <th>svm</th>\n      <td>SVM - Linear Kernel</td>\n      <td>0.6012</td>\n      <td>0.0000</td>\n      <td>0.3728</td>\n      <td>0.5924</td>\n      <td>0.5308</td>\n      <td>0.2779</td>\n      <td>0.3292</td>\n      <td>0.055</td>\n    </tr>\n    <tr>\n      <th>qda</th>\n      <td>Quadratic Discriminant Analysis</td>\n      <td>0.4255</td>\n      <td>0.5416</td>\n      <td>0.3600</td>\n      <td>0.5113</td>\n      <td>0.4394</td>\n      <td>0.0849</td>\n      <td>0.0903</td>\n      <td>0.033</td>\n    </tr>\n    <tr>\n      <th>nb</th>\n      <td>Naive Bayes</td>\n      <td>0.1921</td>\n      <td>0.7366</td>\n      <td>0.5183</td>\n      <td>0.6078</td>\n      <td>0.1391</td>\n      <td>0.0947</td>\n      <td>0.1474</td>\n      <td>0.017</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n                   multi_class='auto', n_jobs=None, penalty='l2',\n                   random_state=1097, solver='lbfgs', tol=0.0001, verbose=0,\n                   warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "grid = setup(data=train, target=train.columns[-1], html=False, silent=True, verbose=False)\n",
    "best = compare_models()\n",
    "print(best)"
   ]
  },
  {
   "source": [
    "As observed in terms of accuracy, Linear Discriminant Analysis outperforms other algorithms. But let us say that we want to use Decision Tree as our classifier instead of LDA and that we want to get the best performance out of it.\n",
    "\n",
    "In order to achieve this, we can apply **hyperparameter tuning**."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from pycaret.classification import tune_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 10 folds for each of 1000 candidates, totalling 10000 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1200 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done 3200 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done 6000 tasks      | elapsed:   22.8s\n",
      "[Parallel(n_jobs=-1)]: Done 9600 tasks      | elapsed:   35.7s\n",
      "[Parallel(n_jobs=-1)]: Done 10000 out of 10000 | elapsed:   37.1s finished\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n0       0.7589  0.7703  0.6215  0.7748  0.7602  0.5527  0.5538\n1       0.7946  0.8770  0.7011  0.7862  0.7858  0.6048  0.6089\n2       0.8304  0.8609  0.7553  0.8336  0.8303  0.6772  0.6787\n3       0.8036  0.8727  0.6684  0.8069  0.8003  0.6208  0.6221\n4       0.8036  0.8174  0.7255  0.7986  0.7976  0.6132  0.6179\n5       0.6875  0.8501  0.6668  0.7200  0.6921  0.4487  0.4555\n6       0.8571  0.8970  0.8124  0.8594  0.8542  0.7298  0.7320\n7       0.8304  0.8645  0.8216  0.8322  0.8302  0.6849  0.6852\n8       0.8571  0.9173  0.7315  0.8941  0.8498  0.7483  0.7608\n9       0.7838  0.8356  0.5618  0.7706  0.7756  0.5817  0.5826\nMean    0.8007  0.8563  0.7066  0.8076  0.7976  0.6262  0.6297\nSD      0.0480  0.0394  0.0768  0.0470  0.0461  0.0844  0.0849",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Accuracy</th>\n      <th>AUC</th>\n      <th>Recall</th>\n      <th>Prec.</th>\n      <th>F1</th>\n      <th>Kappa</th>\n      <th>MCC</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.7589</td>\n      <td>0.7703</td>\n      <td>0.6215</td>\n      <td>0.7748</td>\n      <td>0.7602</td>\n      <td>0.5527</td>\n      <td>0.5538</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.7946</td>\n      <td>0.8770</td>\n      <td>0.7011</td>\n      <td>0.7862</td>\n      <td>0.7858</td>\n      <td>0.6048</td>\n      <td>0.6089</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.8304</td>\n      <td>0.8609</td>\n      <td>0.7553</td>\n      <td>0.8336</td>\n      <td>0.8303</td>\n      <td>0.6772</td>\n      <td>0.6787</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.8036</td>\n      <td>0.8727</td>\n      <td>0.6684</td>\n      <td>0.8069</td>\n      <td>0.8003</td>\n      <td>0.6208</td>\n      <td>0.6221</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.8036</td>\n      <td>0.8174</td>\n      <td>0.7255</td>\n      <td>0.7986</td>\n      <td>0.7976</td>\n      <td>0.6132</td>\n      <td>0.6179</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.6875</td>\n      <td>0.8501</td>\n      <td>0.6668</td>\n      <td>0.7200</td>\n      <td>0.6921</td>\n      <td>0.4487</td>\n      <td>0.4555</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.8571</td>\n      <td>0.8970</td>\n      <td>0.8124</td>\n      <td>0.8594</td>\n      <td>0.8542</td>\n      <td>0.7298</td>\n      <td>0.7320</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.8304</td>\n      <td>0.8645</td>\n      <td>0.8216</td>\n      <td>0.8322</td>\n      <td>0.8302</td>\n      <td>0.6849</td>\n      <td>0.6852</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.8571</td>\n      <td>0.9173</td>\n      <td>0.7315</td>\n      <td>0.8941</td>\n      <td>0.8498</td>\n      <td>0.7483</td>\n      <td>0.7608</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.7838</td>\n      <td>0.8356</td>\n      <td>0.5618</td>\n      <td>0.7706</td>\n      <td>0.7756</td>\n      <td>0.5817</td>\n      <td>0.5826</td>\n    </tr>\n    <tr>\n      <th>Mean</th>\n      <td>0.8007</td>\n      <td>0.8563</td>\n      <td>0.7066</td>\n      <td>0.8076</td>\n      <td>0.7976</td>\n      <td>0.6262</td>\n      <td>0.6297</td>\n    </tr>\n    <tr>\n      <th>SD</th>\n      <td>0.0480</td>\n      <td>0.0394</td>\n      <td>0.0768</td>\n      <td>0.0470</td>\n      <td>0.0461</td>\n      <td>0.0844</td>\n      <td>0.0849</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n                       max_depth=13, max_features=1.0, max_leaf_nodes=None,\n                       min_impurity_decrease=0, min_impurity_split=None,\n                       min_samples_leaf=2, min_samples_split=9,\n                       min_weight_fraction_leaf=0.0, presort='deprecated',\n                       random_state=0, splitter='best')\n"
     ]
    }
   ],
   "source": [
    "# we kept the number of iterations to 1000. Increasing the number of iterations would have an effect on the resulting metrics\n",
    "hyperparameter_tuning = tune_model(DecisionTreeClassifier(random_state=0), n_iter=1000, choose_better=True)\n",
    "print(hyperparameter_tuning)"
   ]
  },
  {
   "source": [
    "We now use the resulting hyperparameters for our model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Classification Model using Hyperparameter Tuned DT"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "source": [
    "Without hyperparameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                precision    recall  f1-score   support\n\n         Happy       0.69      0.58      0.63        31\n       Neutral       0.85      0.93      0.89       246\n     Not Happy       0.85      0.72      0.78       106\nNot Very Happy       0.82      0.82      0.82        17\n\n      accuracy                           0.84       400\n     macro avg       0.81      0.76      0.78       400\n  weighted avg       0.84      0.84      0.84       400\n\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=0)\n",
    "model = dt.fit(x_train, y_train)\n",
    "model.score(x_test, y_test)\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "source": [
    "With hyperparameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "dt = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
    "                       max_depth=13, max_features=1.0, max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0, min_impurity_split=None,\n",
    "                       min_samples_leaf=2, min_samples_split=9,\n",
    "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
    "                       random_state=0, splitter='best')\n",
    "model = dt.fit(x_train, y_train)\n",
    "model.score(x_test, y_test)\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, pred))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                precision    recall  f1-score   support\n\n         Happy       0.85      0.71      0.77        31\n       Neutral       0.87      0.96      0.91       246\n     Not Happy       0.86      0.75      0.80       106\nNot Very Happy       0.91      0.59      0.71        17\n\n      accuracy                           0.87       400\n     macro avg       0.87      0.75      0.80       400\n  weighted avg       0.87      0.87      0.86       400\n\n"
     ]
    }
   ]
  },
  {
   "source": [
    "As we can see, there's a difference when we view the metrics for DT Classifier without tuned hyperparameters and DT Classifier with tuned hyperparameters."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}